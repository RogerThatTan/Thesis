{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Load the best saved model\n",
    "model.load_state_dict(torch.load('best_food_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Full evaluation on test set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Generate classification report\n",
    "class_names = test_dataset.classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis of model confidence\n",
    "confidence_scores = np.max(all_probs, axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(confidence_scores, bins=20, alpha=0.7)\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Model Confidence Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Visualize some predictions\n",
    "def visualize_predictions(model, test_loader, device, class_names, num_images=5):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(nrows=num_images, ncols=2, figsize=(12, 15))\n",
    "    \n",
    "    # Get a batch of test images\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    # Denormalize images\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Original image\n",
    "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Plot image with prediction\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title(f\"True: {class_names[labels[i]]}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Plot confidence scores\n",
    "        probs = torch.nn.functional.softmax(outputs[i], dim=0).cpu().numpy()\n",
    "        top5_probs, top5_indices = torch.topk(torch.from_numpy(probs), 5)\n",
    "        top5_classes = [class_names[idx] for idx in top5_indices]\n",
    "        \n",
    "        y_pos = np.arange(5)\n",
    "        axes[i, 1].barh(y_pos, top5_probs)\n",
    "        axes[i, 1].set_yticks(y_pos)\n",
    "        axes[i, 1].set_yticklabels(top5_classes)\n",
    "        axes[i, 1].set_title('Top 5 Predictions')\n",
    "        axes[i, 1].set_xlim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_loader, device, class_names)\n",
    "\n",
    "# Critical analysis\n",
    "print(\"\\n--- Critical Analysis ---\")\n",
    "print(f\"1. Validation Accuracy is perfect (100%) through all epochs, which is unusual.\")\n",
    "print(f\"2. Training converged extremely quickly, reaching 100% accuracy by epoch 7.\")\n",
    "print(f\"3. Possible explanations:\")\n",
    "print(\"   a. The dataset might be too small or not challenging enough\")\n",
    "print(\"   b. There might be data leakage between train and test sets\")\n",
    "print(\"   c. The classes could be too easily distinguishable\")\n",
    "print(\"   d. The model might be memorizing rather than generalizing\")\n",
    "print(\"\\n4. Recommendations:\")\n",
    "print(\"   a. Test on completely new, unseen images\")\n",
    "print(\"   b. Use more challenging data augmentation\")\n",
    "print(\"   c. Implement cross-validation\")\n",
    "print(\"   d. Consider a more diverse dataset\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
