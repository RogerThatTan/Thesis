{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mport tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import glob as gb \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Force TensorFlow to use CPU only (to avoid GPU issues)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "print(\"Using CPU only mode\")\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "SEED = 1000\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_DIR = '/media/rogerthattan/Toshiba/Thesis/Dataset/Train_Data'\n",
    "TEST_DIR = '/media/rogerthattan/Toshiba/Thesis/Dataset/Test_Data'\n",
    "\n",
    "# Analyze dataset\n",
    "categories = []\n",
    "class_count = []\n",
    "train_exm = 0\n",
    "for f in os.listdir(TRAIN_DIR):\n",
    "    files = gb.glob(pathname=str(TRAIN_DIR + '/' + f + '/*.jpg'))\n",
    "    categories.append(f)\n",
    "    class_count.append(len(files))\n",
    "    train_exm += len(files)\n",
    "\n",
    "# Plot class distribution\n",
    "sns.barplot(x=categories, y=class_count).set_title(\"Distribution of train data\")\n",
    "plt.show()\n",
    "print(f\"Total training examples: {train_exm}\")\n",
    "\n",
    "# Data generators with simpler preprocessing\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.1,\n",
    "    validation_split=0.2,\n",
    "    rescale=1./255  # Simple rescaling instead of complex preprocessing\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_batch = train_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "valid_batch = train_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_batch = test_gen.flow_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(train_batch)\n",
    "validation_steps = len(valid_batch)\n",
    "\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")\n",
    "\n",
    "# Build a simpler ResNet model\n",
    "img_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "num_classes = len(categories)\n",
    "\n",
    "# Use a smaller ResNet model\n",
    "base_model = tf.keras.applications.ResNet50V2(\n",
    "    input_shape=img_shape,\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the complete model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Display model summary\n",
    "print(\"Model created successfully\")\n",
    "\n",
    "# Compile the model with a simpler optimizer\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Try to train with a very small number of steps first to test\n",
    "try:\n",
    "    print(\"Testing model with a small batch...\")\n",
    "    x_sample, y_sample = next(iter(train_batch))\n",
    "    model.fit(x_sample, y_sample, epochs=1, verbose=1)\n",
    "    print(\"Small batch test successful, proceeding with full training\")\n",
    "    \n",
    "    # Train the model\n",
    "    h = model.fit(\n",
    "        train_batch,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_batch,\n",
    "        validation_steps=validation_steps,\n",
    "        epochs=50,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history['accuracy'], 'o-', label='train accuracy')\n",
    "    plt.plot(h.history['val_accuracy'], 'o-', label='validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history['loss'], 'o-', label='train loss')\n",
    "    plt.plot(h.history['val_loss'], 'o-', label='validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "    \n",
    "    # Alternative approach if the above fails\n",
    "    print(\"\\nTrying alternative approach with manual batching...\")\n",
    "    \n",
    "    # Create a simpler model\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "    \n",
    "    simple_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=img_shape),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    simple_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train with the simpler model\n",
    "    h = simple_model.fit(\n",
    "        train_batch,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_batch,\n",
    "        validation_steps=validation_steps,\n",
    "        epochs=20,\n",
    "        callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history for the simple model\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history['accuracy'], 'o-', label='train accuracy')\n",
    "    plt.plot(h.history['val_accuracy'], 'o-', label='validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history['loss'], 'o-', label='train loss')\n",
    "    plt.plot(h.history['val_loss'], 'o-', label='validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "# Save the model\n",
    "try:\n",
    "    model.save('resnet_model.h5')\n",
    "    print(\"Model saved successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")\n",
    "    try:\n",
    "        # Try saving in TensorFlow SavedModel format instead\n",
    "        model.save('resnet_model')\n",
    "        print(\"Model saved in SavedModel format\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error saving in SavedModel format: {e2}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
